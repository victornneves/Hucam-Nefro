accordion / chevron/ mock de dados (dados em JSON) do js pro html. Filtros pro gráfico

LÓGICA:

--> LIMITAR NRO DE TOKENS -> MAS só apos a msg e primer...

Atualmente o chat responde baseado apenas na pergunta do médico, como se ele não tivesse memória da conversa. O desejado é que essas perguntas e respostas anteriores não sejam perdidas, e as próximas respostas do chat gpt não desconsidere o que foi dito anteriormente
-> COMO FAZER ISSO: com role management da API do OpenAI. system, user, assistant.
--> ATENTAR AO MÁXIMO DE TOKENS: em vez de extrapolar o número de tokens, ir excluindo respostas anteriores (por ex.: tenho os roles system, user, assistant, user, assistant, user e o proximo - assistant - vai extrapolar. Então me vez de excluir system, tenho que exluir o primeiro user)
--> o prompt deve ter todo o sumario só na primeria msg, e depois apenas as perguntas

A resposta deve ter uma formatação amigável (o role do system recebe o token que são as diretrizes de como ele deve responder)
-> resposta sucinta, formatada (negrito, espaço, tab), pode mostrar gráficos (por exemplo, da variação de determinado exame de sangue no tempo)
-> API gpt suporta apenas saídas de texto (nao de imagem/ gráfico em forma d imagem)

* Garantir baixa latência na API OpenAI: stream=True para Server-Sent Events (SSE) / Streaming ou usar API em Tempo Real (Realtime API). -> https://platform.openai.com/docs/quickstart?api-mode=chat -> https://platform.openai.com/docs/guides/realtime or https://platform.openai.com/docs/guides/streaming-responses?api-mode=chat 

DESIGN:

design da mensagem formatada -> está sendo exibida em txt (?) -> estarei formatando em markdown?
-> response_format="markdown" em source.py
-> ajeitar html para texto do chat ser formatado em markdown

A mensagem que envio para o chat tem que estar à direita no card, e não na esquerda que nem está. E a mensagem do sistema tem que estar à esquerda (e não à direita que nem está).

--------------------------

Próximos Passos para a Implementação

1. Estrutura de Diretórios:

    modulo_chat/
    ├── templates/
    │   └── index.html
    ├── static/
    │   ├── css/
    │   |   └── style.css
    │   ├── js/
    │   |   └── app.js
    │   └── images/
    ├── source.py
    └── app.py

2. Implementações Necessárias:

    a. Integração com Player de Áudio Real:

        Conectar com o módulo de áudio para controle de reprodução

        Implementar barra de progresso funcional

    b. Carregamento Real de Dados do Paciente:

        Criar endpoint /getPatientData na API

        Buscar informações reais do YAML do paciente

    c. Histórico de Conversa:

        Salvar e carregar histórico de perguntas/respostas

        Adicionar paginação para conversas longas

    d. Melhorias de UI:

        Indicadores de status (conectado, processando)

        Timestamps nas mensagens

        Marcadores de mensagens lidas/não lidas

    e. Segurança:

        Adicionar CORS configuration na API

        Implementar autenticação básica

3. Fluxo Completo de Desenvolvimento:

    1. Testar a interface estática localmente

    2. Conectar com a API Flask (já funciona com o código atual)

    3. Implementar o player de áudio real

    4. Adicionar tratamento de erros robusto

    5. mplementar sistema de histórico

    6. Adicionar features avançadas (anexos, marcações)

    7. Testes finais e ajustes

Extensões Futuras:

    Integração com módulo de agendamento

    Sistema de alertas para valores anormais

    Exportação de relatórios em PDF

    Versão mobile responsiva