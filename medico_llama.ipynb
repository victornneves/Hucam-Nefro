{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def format_dict(data, indent=0):\n",
    "    \"\"\"\n",
    "    Recursively formats a dictionary or list into a readable string.\n",
    "    \"\"\"\n",
    "    formatted = []\n",
    "    prefix = \"  \" * indent  # Indentation for nesting\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            formatted.append(f\"{prefix}{key}:\")\n",
    "            formatted.append(format_dict(value, indent + 1))\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            formatted.append(f\"{prefix}- {format_dict(item, indent + 1).strip()}\")\n",
    "    else:\n",
    "        # For strings, numbers, or other types\n",
    "        formatted.append(f\"{prefix}{data}\")\n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "\n",
    "def readable_string(data):\n",
    "    if isinstance(data, dict):\n",
    "        # return json.dumps(data, indent=2, ensure_ascii=False) \n",
    "        return format_dict(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "# def get_diagnosis(hd):\n",
    "#     try:\n",
    "#         stage = hd[\"estagio_drc\"]\n",
    "#         drc = \"\"\n",
    "#         drc += f\"DRC: G{stage['grau']}\"\n",
    "#         if alb := stage.get(\"albuminuria\"):\n",
    "#             drc += f\"/A{alb}\"\n",
    "#         drc += \"\\nFunção renal atual: \" + stage.get(\"funcao_rim_atual\")\n",
    "#         if et := hd.get(\"etiologia_doença_de_base\"):\n",
    "#             drc += \"\\nEtiologia: \" + et\n",
    "#         return drc\n",
    "#     except TypeError:\n",
    "#         return hd\n",
    "\n",
    "def get_diagnosis(hd):\n",
    "    try:\n",
    "        stage = hd[\"estagio_drc\"]\n",
    "        drc = \"\"\n",
    "        drc += f\"{stage['grau']}\"\n",
    "        if et := hd.get(\"etiologia_doença_de_base\"):\n",
    "            drc += \" \" + et\n",
    "        return drc\n",
    "    except TypeError:\n",
    "        return hd\n",
    "\n",
    "\n",
    "def get_field(summary, field):\n",
    "    field = summary[\"relatorio_consulta_ambulatorial_nefrologia\"][field]\n",
    "    if isinstance(field, list):\n",
    "        field = [readable_string(x) for x in field]\n",
    "        return \"\\n\".join(field)\n",
    "    else:\n",
    "        return field\n",
    "\n",
    "\n",
    "def get_summary(patient_id):\n",
    "    with open(\n",
    "        f\"Dataset-Hucam-Nefro/patient_{patient_id:03d}/patient_{patient_id:03d}_medical_summary.yaml\"\n",
    "    ) as fp:\n",
    "        return yaml.safe_load(fp)\n",
    "    \n",
    "def get_prediction(patient_id):\n",
    "    with open(\n",
    "        f\"results/patient_{patient_id}/outputs.yaml\"\n",
    "    ) as fp:\n",
    "        return yaml.safe_load(fp)\n",
    "\n",
    "def load_yaml(file_path):\n",
    "    \"\"\"Load a YAML file and return its content.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "def get_field(data, field_path):\n",
    "    \"\"\"Safely retrieve a nested field from a dictionary.\"\"\"\n",
    "    keys = field_path.split(\".\")\n",
    "    for key in keys:\n",
    "        data = data.get(key, {})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"dmis-lab/biobert-v1.1\"\n",
    "# model_name = \"Clinical-AI-Apollo/Medical-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def evaluate_patient(patient_id):\n",
    "    \"\"\"Evaluate a single patient's predictions against the ground truth.\"\"\"\n",
    "    # Load YAML files\n",
    "    ground_truth = get_summary(patient_id)\n",
    "    prediction = get_prediction(patient_id)\n",
    "\n",
    "    # Extract \"grau\" (CKD stage)\n",
    "    try:\n",
    "        true_grau = ground_truth[\"relatorio_consulta_ambulatorial_nefrologia\"][\"hipoteses_diagnosticas\"][\"estagio_drc\"][\"grau\"]\n",
    "        pred_grau = prediction[\"hipoteses_diagnosticas\"][\"estagio_drc\"][\"grau\"]\n",
    "    except Exception as e:\n",
    "        true_grau = None\n",
    "        pred_grau = None\n",
    "    \n",
    "\n",
    "    pred_diagnosis = get_diagnosis(prediction[\"hipoteses_diagnosticas\"])\n",
    "    gt_diagnosis = get_diagnosis(ground_truth[\"relatorio_consulta_ambulatorial_nefrologia\"][\"hipoteses_diagnosticas\"])\n",
    "    \n",
    "    # Tokenize and encode\n",
    "    inputs1 = tokenizer(gt_diagnosis, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs2 = tokenizer(\"Origem da doença renal: \" +  pred_diagnosis, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    # inputs2 = tokenizer(pred_diagnosis, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        embedding1 = model(**inputs1).last_hidden_state.mean(dim=1)\n",
    "        embedding2 = model(**inputs2).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Compute similarity (medical semantic similarity)\n",
    "    mss_diagnosis = torch.nn.functional.cosine_similarity(embedding1, embedding2)[0].abs().item()\n",
    "\n",
    "    # Evaluate conducts\n",
    "    gt_conduct = get_field(ground_truth[\"relatorio_consulta_ambulatorial_nefrologia\"], \"conduta\")\n",
    "    pred_conduct = get_field(prediction, \"conduta\")\n",
    "\n",
    "    gt_conduct = [readable_string(x) for x in gt_conduct]\n",
    "    gt_conduct = \"\\n\".join(gt_conduct)\n",
    "\n",
    "    pred_conduct = [readable_string(x) for x in pred_conduct]\n",
    "    pred_conduct = \"\\n\".join(pred_conduct)\n",
    "\n",
    "    inputs1 = tokenizer(gt_conduct, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs2 = tokenizer(pred_conduct, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embedding1 = model(**inputs1).last_hidden_state.mean(dim=1)\n",
    "        embedding2 = model(**inputs2).last_hidden_state.mean(dim=1)\n",
    "        \n",
    "    cond_cosine = torch.nn.functional.cosine_similarity(embedding1, embedding2)[0].abs().item()\n",
    "    \n",
    "    # evalute impression\n",
    "    gt_impression = ground_truth[\"relatorio_consulta_ambulatorial_nefrologia\"][\"impressão\"]\n",
    "    pred_impression = prediction[\"impressão\"]\n",
    "    \n",
    "    if not gt_impression or not pred_impression:\n",
    "        imp_cosine = None\n",
    "    else:\n",
    "        gt_impression = [readable_string(x) for x in gt_impression]\n",
    "        gt_impression = \"\\n\".join(gt_impression)\n",
    "    \n",
    "        pred_impression = [readable_string(x) for x in pred_impression]\n",
    "        pred_impression = \"\\n\".join(pred_impression)\n",
    "        \n",
    "        inputs1 = tokenizer(gt_impression, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        inputs2 = tokenizer(pred_impression, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embedding1 = model(**inputs1).last_hidden_state.mean(dim=1)\n",
    "            embedding2 = model(**inputs2).last_hidden_state.mean(dim=1)\n",
    "            \n",
    "        imp_cosine = torch.nn.functional.cosine_similarity(embedding1, embedding2)[0].abs().item()\n",
    "\n",
    "    # Compile results\n",
    "    return {\n",
    "        \"patient_id\": patient_id,\n",
    "        \"true_stage\": true_grau,\n",
    "        \"estimated_stage\": pred_grau,\n",
    "        \"GT Etiology\": \" \".join(gt_diagnosis.split(' ')[1:]) if len(gt_diagnosis.split(' ')) > 1 else None,\n",
    "        \"Pred Etiology\": \" \".join(pred_diagnosis.split(' ')[1:]) if len(pred_diagnosis.split(' ')) > 1 else None,\n",
    "        \"GT Conduct\": gt_conduct,\n",
    "        \"Pred Conduct\": pred_conduct,\n",
    "        \"GT Impression\": gt_impression,\n",
    "        \"Pred Impression\": pred_impression,\n",
    "        \"diagnosis_mss\": mss_diagnosis,\n",
    "        \"conduct_cosine\": cond_cosine,\n",
    "        \"impression_cosine\": imp_cosine\n",
    "    }\n",
    "\n",
    "\n",
    "# Iterate over patients and compile results\n",
    "results = []\n",
    "for patient_id in range(1, 17):\n",
    "# for patient_id in [10]:\n",
    "    print(f\"Evaluating patient {patient_id}\")\n",
    "    patient_results = evaluate_patient(patient_id)\n",
    "    if patient_results:\n",
    "        results.append(patient_results)\n",
    "\n",
    "df_results = pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
